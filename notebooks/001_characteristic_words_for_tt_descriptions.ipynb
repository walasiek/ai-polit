{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4cff970",
   "metadata": {},
   "source": [
    "Characteristic words from TT descriptions\n",
    "===================================\n",
    "\n",
    "This experiment focuses on the descriptions of the Twitter accounts of Polish Sejm MPs.\n",
    "We ask ourselves are there any characteristic words used in the descriptions.\n",
    "\n",
    "This is first toy example, because the number of descriptions is rather small (<400), so the results are statistically insignificant. Also only the biggest parties were used in the experiment (and only for some we obtained any results). But this is good first try for further more challenging tasks.\n",
    "\n",
    "In the solution I used TF-IDF vectorization of each description, building simple classifier on top of that.\n",
    "Description were preprocessed so only word-alike tokens were left, and transformed to their canonical forms (geting rid of inflection).\n",
    "\n",
    "The classifier (even that it is very simple model) achieved good result on the test set (0.73 f1-score with 6 labels to classify). But the task was pretty much simple - in most cases the descriptions contain direct indication of the MPs affiliation - such words were identified as the top features used in classification. Still there are some other words which were selected as importat features... and those are interesting to check.\n",
    "\n",
    "Data collection: around 2023-01-11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aipolit.utils.text import read_tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to create such file on your own\n",
    "polit_data = read_tsv('../local_data/politycy-dane.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23453a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pretty printing of table data\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_pretty_table(raw_data, header):\n",
    "    df = pd.DataFrame(raw_data, columns=header)\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816008da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source for parts of this code: \n",
    "# https://datascience.stackexchange.com/questions/103735/methods-for-finding-characteristic-words-for-a-group-of-documents-in-comparison\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97991f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for lemmatization\n",
    "import spacy\n",
    "from spacy.lang.pl.examples import sentences\n",
    "\n",
    "nlp_pl = spacy.load(\"pl_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove emojis preprocessing step\n",
    "# Source: https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "import re\n",
    "\n",
    "EMOJI_STRING = \\\n",
    "u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "u\"\\U00002702-\\U000027B0\"\n",
    "u\"\\U00002702-\\U000027B0\"\n",
    "u\"\\U000024C2-\\U0001F251\"\n",
    "u\"\\U0001f926-\\U0001f937\"\n",
    "u\"\\U00010000-\\U0010ffff\"\n",
    "u\"\\u2640-\\u2642\" \n",
    "u\"\\u2600-\\u2B55\"\n",
    "u\"\\u200d\"\n",
    "u\"\\u23cf\"\n",
    "u\"\\u23e9\"\n",
    "u\"\\u231a\"\n",
    "u\"\\ufe0f\"  # dingbats\n",
    "u\"\\u3030\"\n",
    "\n",
    "        \n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\" + EMOJI_STRING + \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove urls\n",
    "# Source:\n",
    "# https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
    "\n",
    "def remove_urls(text):\n",
    "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text, flags=re.MULTILINE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedbdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emails(text):\n",
    "    text = re.sub(r'([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\\.[A-Z|a-z]{2,})+', \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188695b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave only word-alike tokens\n",
    "# remove emojis\n",
    "# run lemmatization\n",
    "\n",
    "def preprocess_sentence(nlp, text):\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_emails(text)\n",
    "    text = re.sub(\"[^\\w]+\", \" \", text)\n",
    "    \n",
    "    print(text)\n",
    "    text = re.sub(r\"^\\s+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+$\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    result = []\n",
    "    doc = nlp_pl(text)\n",
    "    for token in doc:\n",
    "        #print(token.text, token.pos_, token.dep_, token.lemma_)\n",
    "        result.append(token.lemma_)        \n",
    "\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating how preprocessing works\n",
    "sample_sentence = \"2022 ðŸ‡µðŸ‡± Minister ds. Unii Europejskiej #babieslivesmatter http://example.com s@a.com @@@\"\n",
    "#sample_sentence = \"ðŸ‡µðŸ‡±\"\n",
    "#sample_sentence = \"ðŸ˜€\"\n",
    "\n",
    "preprocessed_sentence = preprocess_sentence(nlp_pl, sample_sentence)\n",
    "\n",
    "print(\"Input:\\n  \" + sample_sentence)\n",
    "print(\"\")\n",
    "print(\"After preprocessing:\\n  \" + preprocessed_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading sample data\n",
    "\n",
    "# not enough data for all the parties :(\n",
    "processed_parties = ['PiS', 'PO', 'Lewica', 'Solidarna Polska', 'PSL', 'Polska2050']\n",
    "\n",
    "#processed_parties = ['PiS', 'PO']\n",
    "\n",
    "descriptions_texts = []\n",
    "descriptions_labels = []\n",
    "\n",
    "for e in polit_data:\n",
    "    party = e['party']\n",
    "    desc = e['description']\n",
    "    if not desc:\n",
    "        continue\n",
    "\n",
    "    if party in processed_parties:\n",
    "        desc = preprocess_sentence(nlp_pl, desc)\n",
    "        # We take only descriptons with at least 10 characters\n",
    "        if len(desc) < 10:\n",
    "            continue\n",
    "        descriptions_texts.append(desc)\n",
    "        descriptions_labels.append(party)  \n",
    "        \n",
    "print(\"Descriptions:\", len(descriptions_texts))\n",
    "print(\"Labels:\", len(descriptions_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0208342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "def show_label_distribution():\n",
    "    print(\"Label distribution\")\n",
    "\n",
    "    label_count = Counter()\n",
    "    for label in descriptions_labels:\n",
    "        label_count[label] += 1\n",
    "    \n",
    "    raw_data = []\n",
    "    for label, value in label_count.items():\n",
    "        raw_data.append((label, value))\n",
    "    show_pretty_table(raw_data, [\"Label\", \"Count\"])\n",
    "    \n",
    "show_label_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e49f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample descriptions:\")\n",
    "desc_and_labels = [(d, l) for d, l in zip(descriptions_texts, descriptions_labels)]\n",
    "\n",
    "def show_desc_sample():\n",
    "    data = []\n",
    "    for entry in random.sample(desc_and_labels, k=10):\n",
    "        desc = entry[0]\n",
    "        label = entry[1]\n",
    "        data.append((label, desc))\n",
    "    show_pretty_table(data, ['label', 'tt description'])  \n",
    "\n",
    "show_desc_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build classifier\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    min_df=0.001, max_df=0.2, max_features=10_000, ngram_range=(1, 3),\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\") # one char tokens are also valid\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    descriptions_texts,\n",
    "    descriptions_labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42)\n",
    "\n",
    "\n",
    "X_train_tfidf_matrix = tfidf.fit_transform(X_train)\n",
    "\n",
    "# 2. Train classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_tfidf_matrix, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline = make_pipeline(tfidf, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f37ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample classifier predictions on TEST set\n",
    "\n",
    "def show_sample_predictions():\n",
    "    MAX_SAMPLE_TO_SHOW = 100\n",
    "\n",
    "    #X_test_tfidf_matrix = tfidf.transform(X_test[0:MAX_SAMPLE_TO_SHOW])\n",
    "    #y_test_actual = clf.predict(X_test_tfidf_matrix)\n",
    "\n",
    "    y_test_actual = clf_pipeline.predict(X_test[0:MAX_SAMPLE_TO_SHOW])\n",
    "    raw_data = []\n",
    "    for desc, pred_actual, pred_expected in zip(\n",
    "        X_test[0:MAX_SAMPLE_TO_SHOW],\n",
    "        y_test_actual,\n",
    "        y_test[0:MAX_SAMPLE_TO_SHOW],\n",
    "    ):\n",
    "        PRED_STATUS = \"FAIL\"\n",
    "        if pred_actual == pred_expected:\n",
    "            PRED_STATUS = \"SUCCESS\"\n",
    "        raw_data.append((PRED_STATUS, pred_actual, pred_expected, desc))\n",
    "    show_pretty_table(raw_data, ['Result', \"Actual\", \"Expected\", \"TT Description\"])\n",
    "    \n",
    "        \n",
    "show_sample_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c69f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score of the classifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def show_score(clf, X_input, y_expected, dataset_name):\n",
    "    y_actual = clf_pipeline.predict(X_input)\n",
    "    score = precision_recall_fscore_support(y_expected, y_actual, average='weighted')\n",
    "    print(f\"Score for {dataset_name} is:\")\n",
    "    print(f\"  precistion: {score[0]}\")\n",
    "    print(f\"  recall: {score[1]}\")\n",
    "    print(f\"  f-score: {score[2]}\")\n",
    "    print(f\"  Support: {score[3]}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_expected, y_actual, target_names=clf.classes_))\n",
    "    \n",
    "show_score(clf, X_train, y_train, \"TRAIN SET\")\n",
    "show_score(clf, X_test, y_test, \"TEST SET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11935595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "print(\"Feature count:\", len(feature_names))\n",
    "print(\"Number of stopwords:\", len(tfidf.stop_words_))\n",
    "#print(\"Stopwords:\", tfidf.stop_words_)\n",
    "#print(\"Features:\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_FEATURES = 50 # Top N features to be considered\n",
    "MIN_CONFIDENCE = 0.6 # Take only results with high confidence\n",
    "\n",
    "# 3. Get feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# 4. Sort and get important features\n",
    "word_indices = np.argsort(feature_importances)[::-1] # using argsort we get indices of important features\n",
    "\n",
    "top_words_per_class = defaultdict(list)\n",
    "\n",
    "for word_idx in word_indices[:TOP_N_FEATURES]:\n",
    "    word = feature_names[word_idx]\n",
    "    clf_input = [word]\n",
    "    #word_class = clf.predict(tfidf.transform(clf_input))[0]\n",
    "    class_probs = clf_pipeline.predict_proba(clf_input)[0]\n",
    "    class_idx = np.argmax(class_probs)\n",
    "    class_prob = class_probs[class_idx]\n",
    "    if class_prob < MIN_CONFIDENCE:\n",
    "        continue\n",
    "    word_class = clf.classes_[class_idx]    \n",
    "    top_words_per_class[word_class].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, top_words in top_words_per_class.items():\n",
    "    print(f\"Top words characteristic for class: {label}\")\n",
    "    for word in top_words:\n",
    "        print(f\"  {word}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa891bc",
   "metadata": {},
   "source": [
    "LIME Explanations\n",
    "===============\n",
    "\n",
    "Another approach how to identify which words are \"characteristic\" to given class is to use Explainable AI techniques in order to find which features are the most commonly used for the \"correct\" decision.\n",
    "\n",
    "We will use LIME alogrithm in this experiment.\n",
    "\n",
    "The general idea is as follows:\n",
    "\n",
    "1. Run explainer on each entry in both test/train set\n",
    "2. For each explanation process only those which are correct, and have \"high\" confidence\n",
    "3. Check top input features (words) contributing to final score (removing those with low weight - another hyperparam)\n",
    "4. Count each feature as keyword candidate\n",
    "5. Show most common keywords collected for each label.\n",
    "\n",
    "This method has its advantage over previous \"naive\" approach, as it allows to think about keywords \"independently\" between classes. It may appear that some words (especially for parties with similar idealogy) can be keywords for multiple parties. In that cases they will appear on the different lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00895c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775095a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LimeTextExplainer(class_names=clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_single(index):\n",
    "    print(f\"Expected label: {descriptions_labels[index]}\")\n",
    "    exp = explainer.explain_instance(descriptions_texts[index], clf_pipeline.predict_proba, num_features=10, top_labels=2)\n",
    "    exp.show_in_notebook(text=True)\n",
    "    \n",
    "explain_single(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 41\n",
    "exp = explainer.explain_instance(descriptions_texts[index], clf_pipeline.predict_proba, num_features=10, top_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ef476",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1359770",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_class_to_index = dict()\n",
    "for i, exp_class in enumerate(exp.class_names):\n",
    "    exp_class_to_index[exp_class] = i\n",
    "    \n",
    "print(exp_class_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_extracted_keywords =defaultdict(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORD_THRESHOLD = 0.02\n",
    "PRED_THRESHOLD = 0.7\n",
    "\n",
    "def is_pred_confident_enough(exp, y_expected):\n",
    "    class_idx = exp_class_to_index[y_expected]\n",
    "    prob = exp.predict_proba\n",
    "    if prob[class_idx] >= PRED_THRESHOLD:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def explain_all(X, y_true):\n",
    "    for x, y_exp in tqdm(zip(X, y_true)):\n",
    "        exp = explainer.explain_instance(\n",
    "            x, \n",
    "            clf_pipeline.predict_proba, \n",
    "            num_features=10, \n",
    "            top_labels=2)\n",
    "        \n",
    "        # only take if prediction is correct and higher than thershold\n",
    "        if not is_pred_confident_enough(exp, y_exp):\n",
    "            continue\n",
    "        for keyword, score in exp.as_list(label=exp_class_to_index[y_exp]):\n",
    "            if score > KEYWORD_THRESHOLD:\n",
    "                exp_extracted_keywords[y_exp][keyword] += 1        \n",
    "        \n",
    "#explain_all(X_test, y_test)\n",
    "explain_all(descriptions_texts, descriptions_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, counter in exp_extracted_keywords.items():\n",
    "    print(f\"Label: {label}\")\n",
    "    for word, freq in counter.most_common(n=10):\n",
    "        print(f\"{word} => {freq}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e896b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-polit",
   "language": "python",
   "name": "ai-polit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
