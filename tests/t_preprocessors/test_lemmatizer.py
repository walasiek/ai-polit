import pytest
from aipolit.preprocessors.lemmatizer import PLLemmatizer


@pytest.mark.parametrize(
    "input_text, expected_text",
    [
        ("Ala ma kota", "ala mieÄ‡ kot"),
        ("Ala ma kota ğŸ˜€", "ala mieÄ‡ kot ğŸ˜€"),
        ("Ala ma kota #kÅ‚amstwa", "ala mieÄ‡ kot # kÅ‚amstwo"),
        ("Ala ma @KÅ‚amstwa", "ala mieÄ‡ @KÅ‚amstwo"),
        ("Kiedy biegaÅ‚aÅ› z Marcinem?", "kiedy biegaÄ‡ z Marcin ?"),
        ("Kiedy byÅ‚aÅ› z Marcinem?", "kiedy byÄ‡ z Marcin ?"),
        ("Kiedy byliÅ›my z Marcinem?", "kiedy byÄ‡ z Marcin ?"),
    ])
def test_simple_pl_lemmatizer(input_text, expected_text):
    lemmatizer = PLLemmatizer.get_instance()

    actual = lemmatizer.process_text(
        input_text,
        ignore_tt_usernames_and_hashes=False,
        ignore_emojis=False,
    )

    assert expected_text == actual


@pytest.mark.parametrize(
    "input_text, expected_text",
    [
        ("Ala ma kota #kÅ‚amstwa", "ala mieÄ‡ kot #kÅ‚amstwa"),
        ("Ala ma @KÅ‚amstwa", "ala mieÄ‡ @KÅ‚amstwa"),
    ])
def test_pl_lemmatizer_preserve_hashes(input_text, expected_text):
    lemmatizer = PLLemmatizer.get_instance()

    actual = lemmatizer.process_text(
        input_text,
        ignore_tt_usernames_and_hashes=True,
        ignore_emojis=False,
    )

    assert expected_text == actual


@pytest.mark.parametrize(
    "input_text, expected_text",
    [
        ("Ala ma kota ğŸ˜€", "ala mieÄ‡ kot ğŸ˜€"),
    ])
def test_pl_lemmatizer_preserve_emojis(input_text, expected_text):
    lemmatizer = PLLemmatizer.get_instance()

    actual = lemmatizer.process_text(
        input_text,
        ignore_tt_usernames_and_hashes=False,
        ignore_emojis=True,
    )

    assert expected_text == actual
